{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "input_size = 16\n",
    "num_fillings = [8, 8]\n",
    "\n",
    "samples = torch.zeros(num_samples, 2 * input_size, dtype=torch.int)\n",
    "# The first num_fillings[0] represents the filled sites for spin up\n",
    "positions_up = torch.randperm(input_size)\n",
    "# The next num_fillings[1] represents the filled sites for spin down\n",
    "positions_down = torch.randperm(input_size)\n",
    "prob_old = 1\n",
    "for i in range(num_samples):\n",
    "    # Metropolis-Hastings\n",
    "    ## Randomly select n out of L occupied sites and n unoccupied sites to swap.\n",
    "    ## As the number of up spins and down spins are converved separately,\n",
    "    ## we swap the occupied and unoccupied sites for each spin separately.\n",
    "    n = 1\n",
    "    ### For spin up\n",
    "    indices_up_occupied = torch.randperm(num_fillings[0])[:n]\n",
    "    indices_up_unoccupied = torch.randperm(input_size - num_fillings[0])[:n] + num_fillings[0]           \n",
    "    elements_up_occupied = positions_up[indices_up_occupied]\n",
    "    elements_up_unoccupied = positions_up[indices_up_unoccupied]\n",
    "    ### For spin down\n",
    "    indices_down_occupied = torch.randperm(num_fillings[1])[:n]\n",
    "    indices_down_unoccupied = torch.randperm(input_size - num_fillings[1])[:n] + num_fillings[1]           \n",
    "    elements_down_occupied = positions_down[indices_down_occupied]\n",
    "    elements_down_unoccupied = positions_down[indices_down_unoccupied]\n",
    "    ## Clone the occupied and unoccupied sites, and swap the elements\n",
    "    new_positions_up = positions_up.clone()\n",
    "    new_positions_up[indices_up_occupied] = elements_up_unoccupied\n",
    "    new_positions_up[indices_up_unoccupied] = elements_up_occupied\n",
    "\n",
    "    new_positions_down = positions_down.clone()\n",
    "    new_positions_down[indices_down_occupied] = elements_down_unoccupied\n",
    "    new_positions_down[indices_down_unoccupied] = elements_down_occupied\n",
    "    # Create the new configuration\n",
    "    config = torch.ones(2 * input_size, dtype=torch.float)\n",
    "    config[new_positions_up[num_fillings[0]:]] = -1\n",
    "    config[new_positions_down[num_fillings[1]:] + input_size] = -1\n",
    "    #print(sum(config))\n",
    "\n",
    "\n",
    "    #out_config_up, out_config_down = forward(config.unsqueeze(0))\n",
    "    out_config_up = torch.rand(1, input_size, num_fillings[0])\n",
    "    out_config_down = torch.rand(1, input_size, num_fillings[1])\n",
    "    \n",
    "    # Calculate the acceptance probability\n",
    "    overlap_up = torch.det(out_config_up[:, new_positions_up[:num_fillings[0]], :])\n",
    "    overlap_down = torch.det(out_config_down[:, new_positions_down[:num_fillings[1]], :])\n",
    "    overlap = torch.abs(overlap_up * overlap_down) ** 2\n",
    "\n",
    "    prob_new = overlap[0].item()\n",
    "    if i == 0:\n",
    "        prob_old = prob_new\n",
    "    # Accept or reject the new configuration\n",
    "    if torch.rand(1).item() < prob_new / prob_old:\n",
    "        new_positions_up = positions_up\n",
    "        new_positions_down = positions_down\n",
    "        prob_old = prob_new\n",
    "        samples[i, :] = config\n",
    "    else:\n",
    "        samples[i, :] = samples[i-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(samples,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "linalg.det: A must be batches of square matrices, but they are 0 by 3 matrices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m c \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnonzero(b, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m c[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdet\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: linalg.det: A must be batches of square matrices, but they are 0 by 3 matrices"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4,3,3)\n",
    "b = torch.zeros(4,3)\n",
    "c = torch.nonzero(b, as_tuple=True)\n",
    "c[1].shape\n",
    "torch.det(a[:,c[1],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 3],\n",
      "        [0, 5],\n",
      "        [1, 2],\n",
      "        [1, 4],\n",
      "        [1, 5],\n",
      "        [2, 0],\n",
      "        [2, 2],\n",
      "        [2, 5]])\n",
      "tensor([[[1., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3,6)\n",
    "a[0,torch.randperm(6)[:3]] = 1\n",
    "a[1,torch.randperm(6)[:3]] = 1\n",
    "a[2,torch.randperm(6)[:3]] = 1\n",
    "#print(a)\n",
    "true_indices = torch.nonzero(a)\n",
    "print(true_indices)\n",
    "num_fillings = len(true_indices)\n",
    "b = torch.zeros(a.size(0), a.size(1), num_fillings//a.size(0))\n",
    "last_dim_indices = (torch.arange(num_fillings) % (num_fillings//a.size(0)))\n",
    "\n",
    "b[true_indices[:, 0], true_indices[:, 1], last_dim_indices] = 1\n",
    "#b[true_indices[:, 0],true_indices[:, 1], torch.tensor([0,1,2,0,1,2])] = 1\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.zeros(a.size(0), a.size(1), 3)\n",
    "\n",
    "# 生成最后一维的索引\n",
    "last_dim_indices = (torch.arange(num_fillings) % 3)[:num_fillings]  # 形状 (num_fillings,)\n",
    "last_dim_indices = last_dim_indices.unsqueeze(1)  # 增加一个维度以便广播\n",
    "\n",
    "# 使用 scatter_ 填充\n",
    "b[true_indices[:, 0], true_indices[:, 1], last_dim_indices.squeeze()] = 1\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
